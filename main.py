# -*- coding: utf-8 -*-
"""PM2.5 using Gated Recurrent Unit (GRU) on Bangkok DataSet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UGNdqhP36YYbZd8cSLGVAgQjv8TeahWf

# PM 2.5 Forecasting (Traning and Testing Version #0.1)

# DataMind Lab, Chula 2021

![](https://www.chula.ac.th/wp-content/uploads/2020/01/WEB_unicef-Chula-PM2.5-EN-scaled.jpg)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler,MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, Input, Lambda, LeakyReLU, Conv1D, MaxPooling1D, Flatten, RepeatVector, BatchNormalization, TimeDistributed
from tensorflow.keras.optimizers import Adam, SGD, Adagrad, RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
#from tensorflow.keras.utils.vis_utils import model_to_dot, plot_model

from datetime import date, timedelta, datetime, date
import itertools
import configparser

from scipy.special import boxcox, inv_boxcox
# %matplotlib inline

def get_data(province) :
    
    'train section'
    train_df = pd.read_csv(f'dataset/train/{province}.csv')
    
    'test section'  
    test_df = pd.read_csv(f'dataset/test/{province}.csv')
    
    return train_df, test_df

train_df, test_df = get_data(province = 'Bangkok')

train_df

train_df['datetime'] = pd.to_datetime(train_df['datetime'])
test_df['datetime'] = pd.to_datetime(test_df['datetime'])
train_df.set_index(train_df['datetime'],inplace=True)
test_df.set_index(test_df['datetime'],inplace=True)

train_df.drop(columns={'datetime'},inplace=True)
test_df.drop(columns={'datetime'},inplace=True)

train_df.columns

ft_cols = ['PM2.5(µg/m3)', 'PM10_mask', 'Temp(C)', 'WindDir', 'Wind Speed(km/h)']
train_df = train_df[ft_cols]
test_df = test_df[ft_cols]

train = train_df
scalers={}

for i in train_df.columns:
    scaler = MinMaxScaler(feature_range=(0,1))
    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))
    s_s=np.reshape(s_s,len(s_s))
    scalers['scaler_'+ i] = scaler
    train[i]=s_s

test = test_df
for i in test_df.columns:
    scaler = scalers['scaler_'+i]
    s_s = scaler.transform(test[i].values.reshape(-1,1))
    s_s=np.reshape(s_s,len(s_s))
    scalers['scaler_'+i] = scaler
    test[i]=s_s

def split_series(series, n_past, n_future):
  X, y = list(), list()
  for window_start in range(len(series)):
    past_end = window_start + n_past
    future_end = past_end + n_future
    if future_end > len(series):
      print(future_end)
    if future_end > len(series):
      break
    past, future = series[window_start:past_end], series[past_end:future_end, 0]
    X.append(past)
    y.append(future)
  return np.array(X), np.array(y)

X_train, y_train = split_series(train.values,24, 72)
X_train = X_train.reshape(X_train.shape[0],X_train.shape[1], X_train.shape[2])
print(X_train.shape,y_train.shape)

X_test, y_test = split_series(test.values,24, 72)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1], X_test.shape[2])
print(X_test.shape,y_test.shape)

opt_params = { #optimizer params
    'lr' : 0.0001, 
    'beta_1' : 0.9,
    'beta_2' : 0.999,
}
opt = Adam(**opt_params)

def GRU_model(n_ft = 5, n_past = 24, n_future = 72):
    
    model = Sequential()
    model.add(GRU(128,input_shape=(n_past,n_ft)))
    model.add(Dense(n_future))
    model.compile(loss = 'mse', optimizer=opt, metrics=['mae'])
    
    return model

gru = GRU_model(n_past=24,n_future=72)

es = EarlyStopping(monitor='val_loss', mode='min', patience=40, verbose=1, restore_best_weights=True)
mcp_save = ModelCheckpoint('model_weights/BKK_GRU.hdf5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)

history_gru = gru.fit(X_train, y_train, epochs=400, batch_size=128, 
                    verbose=1, validation_split=0.2,
                    callbacks=[mcp_save])

train_mae = history_gru.history['loss']
valid_mae = history_gru.history['val_loss']
plt.plot(train_mae, label='train loss'), 
plt.plot(valid_mae, label='validation loss')
plt.ylabel('mse')
plt.xlabel('epoch')
plt.title('train vs. validation accuracy (mse)')
plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)
plt.show()

gru.load_weights("model_weights/BKK_GRU.hdf5")

pred = gru.predict(X_test)

X_test

scaler = scalers['scaler_PM2.5(µg/m3)']
pred=scaler.inverse_transform(pred)
y_test=scaler.inverse_transform(y_test)

#visualize pred on test set +71 step
from matplotlib.pyplot import figure
figure(num=None, figsize=(18, 6), dpi=80, facecolor='w', edgecolor='k')
plt.plot(y_test[:,71],'g',label='ground truth')
plt.plot(pred[:,71],'r',label='predict')
plt.title("pm2.5 forecast (ug/m3)")
plt.legend(loc="upper right")

#visualize prediction on random batch (test set)
plt.plot(y_test[60,:],'g',label='ground truth')
plt.plot(pred[60,:],'r',label='pred')

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error , mean_absolute_error
import math
print("MAE : ",mean_absolute_error(y_test[:,:],pred[:,:]),end=", ")
print("RMSE : ",math.sqrt(mean_squared_error(y_test[:,:],pred[:,:])))

import numpy as np
import itertools
from sklearn.metrics import f1_score
from sklearn.metrics import average_precision_score

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def single_mean_absolute_percentage_error(y_true, y_pred,i): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100
def evaluate_level(inv_ytest,inv_yhat,i):
  high_ytest = []
  med_ytest = []
  low_ytest = []
  high_yhat = []
  med_yhat = []
  low_yhat = []
  for index,val in enumerate(inv_ytest[:,i,0]):
    if val < 35.5:
      low_ytest.append(val)
      low_yhat.append(inv_yhat[index,i,0])     
    elif 35.5 <= val < 55.5:
      med_ytest.append(val)  
      med_yhat.append(inv_yhat[index,i,0])    
    elif val >= 55.5:
      high_ytest.append(val)
      high_yhat.append(inv_yhat[index,i,0])

  high_ytest = np.array(high_ytest)
  high_yhat = np.array(high_yhat)
  med_ytest = np.array(med_ytest)
  med_yhat = np.array(med_yhat)
  low_ytest = np.array(low_ytest)
  low_yhat = np.array(low_yhat)

  print('High level RMSE: %.3f' % math.sqrt(mean_squared_error(np.array(high_ytest), np.array(high_yhat))))
  print('High level MAE: %.3f' % mean_absolute_error(high_ytest, high_yhat))
  print('High level MAPE: %.3f' % single_mean_absolute_percentage_error(high_ytest, high_yhat,i))
  
  print('Med level RMSE: %.3f' % math.sqrt(mean_squared_error(np.array(med_ytest), np.array(med_yhat))))
  print('Med level MAE: %.3f' % mean_absolute_error(med_ytest, med_yhat))
  print('Med level MAPE: %.3f' % single_mean_absolute_percentage_error(med_ytest, med_yhat,i))
    
  print('low level RMSE: %.3f' % math.sqrt(mean_squared_error(np.array(low_ytest), np.array(low_yhat))))
  print('low level MAE: %.3f' % mean_absolute_error(low_ytest, low_yhat))
  print('low level MAPE: %.3f' % single_mean_absolute_percentage_error(low_ytest, low_yhat,i))

def generate_class(inv_ytest,inv_yhat,i):
    class_ytest = []
    class_yhat = []
    #print(inv_ytest[:,i,0])
    #print(inv_yhat[:,i,0])

    for index,val in enumerate(inv_ytest[:,i,0]):
        if val < 35.5:
            class_ytest.append(0)
        elif 35.5 <= val <= 55.5:
            class_ytest.append(1)     
        elif val > 55.5:
            class_ytest.append(2) 
    for index,val in enumerate(inv_yhat[:,i,0]):
        if val < 35.5:
            class_yhat.append(0)   
        elif 35.5 <= val <= 55.5:
            class_yhat.append(1)     
        elif val > 55.5:
            class_yhat.append(2)
    target_names = ['Low AQI','Medium AQI','High AQI']
    print('')
    cls_report = classification_report(class_ytest, class_yhat, target_names=target_names,output_dict=True)
    print(classification_report(class_ytest, class_yhat, target_names=target_names))
    conf = confusion_matrix(class_ytest, class_yhat)
    plt.figure()
    plot_confusion_matrix(conf,classes=['Low AQI','Med AQI','High AQI'])
    plt.show()
    return cls_report
    
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        #print("Normalized confusion matrix")
    else:
        print('')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error , mean_absolute_error
import math

result = []
for j in range(0,72):
  if j == 0 or j == 5 or j== 11 or j == 23 or j == 47 or j==71:
    score = math.sqrt(mean_squared_error(y_test[:,j],pred[:,j]))
    result.append(score)
    cls_report = generate_class(y_test.reshape(y_test.shape[0],y_test.shape[1],1),pred.reshape(pred.shape[0],pred.shape[1],1),j)
    f1_acc = cls_report['accuracy']
    macro = cls_report['macro avg']
    macro_f1 = macro['f1-score']
    result.append(f1_acc)
    result.append(macro_f1)
  print("Day ",j,":")
  print("MAE : ",mean_absolute_error(y_test[:,j],pred[:,j]),end=", ")
  print("RMSE : ",math.sqrt(mean_squared_error(y_test[:,j],pred[:,j])))
  evaluate_level(y_test.reshape(y_test.shape[0],y_test.shape[1],1),pred.reshape(pred.shape[0],pred.shape[1],1),j)
  generate_class(y_test.reshape(y_test.shape[0],y_test.shape[1],1),pred.reshape(pred.shape[0],pred.shape[1],1),j)
  print("====================================================")
print(result)

result_df = pd.DataFrame(data=[result],index=['GRU Bangkok'],columns=['RMSE t+1','f1 acc t+1','macro avg t+1','RMSE t+6','f1 acc t+6','macro avg t+6','RMSE t+12','f1 acc t+12','macro avg t+12','RMSE t+24','f1 acc t+24','macro avg t+24','RMSE t+48','f1 acc t+48','macro avg t+48','RMSE t+72','f1 acc t+72','macro avg t+72',])
result_df

result_df.to_csv('results/GRU Bangkok.csv')

import json
province = 'Bangkok'
path = 'model_weights'
gru.save(f'''{path}/{province}''')

model_config = {
    'ft_cols' : ft_cols,
    'opt_name' : 'Adam',
    'batch_size' : 128,
    'learning rate' : 0.0001,
    'province': province,
    'lag' : 24,
    'n_neurons' : 128,
    'n_ft' : 6,
    'forecast' : 72,
}

config_path = 'config'
config_name = f'{config_path}/{province}_config.json'
with open(config_name, 'w') as json_file :
    json.dump(model_config, json_file)

